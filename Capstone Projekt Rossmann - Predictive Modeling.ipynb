{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Projekt Rossmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of models that will be tested to predict the sales of Rossmann stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Models:\n",
    "\n",
    "Linear Regression: If the relationship between the predictors and the sales is linear, linear regression can be a good starting point.\n",
    "Ridge/Lasso Regression: These are variations of linear regression that include regularization to prevent overfitting, especially useful if you have many predictors.\n",
    "Tree-based Models:\n",
    "\n",
    "Decision Trees: Good for capturing non-linear relationships but can overfit.\n",
    "Random Forest: An ensemble of decision trees, it is more robust and less likely to overfit than a single decision tree.\n",
    "Gradient Boosting Machines (GBM): Models like Gradient Boosting Regressor or XGBoost, LightGBM, and CatBoost are powerful for capturing complex patterns in data.\n",
    "Support Vector Machines (SVM):\n",
    "\n",
    "SVR (Support Vector Regression): Effective in high-dimensional spaces and with kernel functions, it can capture complex relationships.\n",
    "Nearest Neighbors:\n",
    "\n",
    "K-Nearest Neighbors (KNN): Can be used for regression; it predicts the value based on the 'k' closest points.\n",
    "Time Series Specific Models (Not in Scikit-learn but worth considering):\n",
    "\n",
    "ARIMA/SARIMA: Traditional time series models suitable for univariate time series.\n",
    "Prophet: Developed by Facebook, good for daily data with multiple seasonality and holiday effects.\n",
    "LSTM/GRU (Deep Learning): RNNs like LSTM or GRU can be effective, especially if you have a large amount of historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression Models:  \n",
    "\t- Linear Regression\n",
    "\t- Ridge Regression\n",
    "\t- Lasso Regression\n",
    "\n",
    "- Tree-based Models:\n",
    "\t- Decision Trees\n",
    "\t- Random Forest\n",
    "\t- Gradient Boosting Machines (GBM) (in scikit-learn: GradientBoostingRegressor)\n",
    "\n",
    "- Support Vector Machines (SVM):\n",
    "\t- SVR (Support Vector Regression)\n",
    "\n",
    "- Nearest Neighbors:\n",
    "\t- K-Nearest Neighbors (KNN)\n",
    "\n",
    "- Neural Networks:\n",
    "\t- MLP (Multi-layer Perceptron)\n",
    "\n",
    "- Time Series Specific Models:\n",
    "\t- ARIMA/SARIMA\n",
    "\t- Prophet\n",
    "\t- LSTM/GRU (Deep Learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use:\n",
    "- LinearRegression\n",
    "- RidgeRegression\n",
    "- LassoRegression\n",
    "- DecisionTreeRegressor\n",
    "- RandomForestRegressor\n",
    "- GradiantBoostingRegressor\n",
    "- SVR\n",
    "- KNN\n",
    "- MLPRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of KPIs for model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Absolute Error (MAE): The average of the absolute differences between predictions and actual values. It gives an idea of the magnitude of the error, but no information about the direction (over or under predicting).\n",
    "- Mean Squared Error (MSE): The average of the squared differences between predictions and actual values. It gives more weight to larger errors and is more useful in practice than MAE.\n",
    "- Root Mean Squared Error (RMSE): The square root of the MSE, it is more interpretable than the MSE as it is in the same units as the response variable.\n",
    "- R-squared (R2): The proportion of the variance in the dependent variable that is predictable from the independent variables. It provides an indication of the goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.\n",
    "- Adjusted R-squared: The R-squared value adjusted for the number of predictors in the model. It is useful for comparing models with different numbers of predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test models with test and tain data. Test includes the last 8 weeks from each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test models with test and tain data. Test includes the last 8 weeks from each store\n",
    "\n",
    "def testModelsTestSplit8W(df, scaler):\n",
    "\ttrain_data = []\n",
    "\ttest_data = []\n",
    "\n",
    "\t# Group by store and split into training and test data\n",
    "\tamount_test_weeks = 8\n",
    "\tfor store_id, group in df.groupby('Store'):\n",
    "\t\ttrain_data.append(group[: -amount_test_weeks])\n",
    "\t\ttest_data.append(group[-amount_test_weeks:])\n",
    "\n",
    "\t# Combine the list entries to one dataframe\n",
    "\ttrain_df = pd.concat(train_data)\n",
    "\ttest_df = pd.concat(test_data)\n",
    "\n",
    "\t# Create feature and target data frames\n",
    "\tX_train = train_df.drop(columns=['Future_Sales'])\n",
    "\ty_train = train_df['Future_Sales']\n",
    "\tX_test = test_df.drop(columns=['Future_Sales'])\n",
    "\ty_test = test_df['Future_Sales']\n",
    "\n",
    "\t# Scaling of the data\n",
    "\tif scaler:\n",
    "\t\tX_train = scaler.fit_transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\tdef adj_r2_score(model, X, y):\n",
    "\t\tn = X.shape[0]\n",
    "\t\tp = X.shape[1]\n",
    "\t\tr2 = r2_score(y, model.predict(X))\n",
    "\t\treturn 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "\t# Defining the models to test\n",
    "\tmodels = [\n",
    "\t\t('LinearRegression', LinearRegression(n_jobs=-1)),\n",
    "\t\t#('RidgeRegression', Ridge(random_state=42)),\n",
    "\t\t#('LassoRegression', Lasso(random_state=42)),\n",
    "\t\t#('DecisionTreeRegressor', DecisionTreeRegressor(random_state=42)),\n",
    "\t\t#('RandomForestRegressor', RandomForestRegressor(n_jobs=-1, max_depth=10, random_state=42, n_estimators=100)),\n",
    "\t\t#('SVR', SVR()),\n",
    "\t\t#('KNN', KNeighborsRegressor())\n",
    "\t]\n",
    "\n",
    "\tresults = []\n",
    "\t# Train models and calculate metrics\n",
    "\tfor name, model in models:\n",
    "\t\tmodel.fit(X_train, y_train)\n",
    "\t\ty_train_pred = model.predict(X_train)\n",
    "\t\ty_test_pred = model.predict(X_test)\n",
    "\n",
    "\t\tresults.append({\n",
    "\t\t\t'Model': name,\n",
    "\t\t\t'RMSE_Train': sqrt(mse(y_train, y_train_pred)),\n",
    "\t\t\t'MAE_Train': mae(y_train, y_train_pred),\n",
    "\t\t\t'R2_Train': r2_score(y_train, y_train_pred),\n",
    "\t\t\t'Adj_R2_Train': adj_r2_score(model, X_train, y_train),\n",
    "\t\t\t'RMSE_Test': sqrt(mse(y_test, y_test_pred)),\n",
    "\t\t\t'MAE_Test': mae(y_test, y_test_pred),\n",
    "\t\t\t'R2_Test': r2_score(y_test, y_test_pred),\n",
    "\t\t\t'Adj_R2_Test': adj_r2_score(model, X_test, y_test)\n",
    "\t\t})\n",
    "\t\t#print last result\n",
    "\t\tprint(results[-1])\n",
    "\n",
    "\tresults_df = pd.DataFrame(results)\n",
    "\treturn results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates x splits in test and train where the last 8 weeks of each store are included in the respective test split and the splits are distributed evenly using gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates x splits in test and train where the last 8 weeks of each store are included in the respective test split and the splits are distributed\n",
    "# evenly using gap\n",
    "\n",
    "def testModelsCV8W(df, scaler):\n",
    "\n",
    "    n_splits = 5\n",
    "    window_size = 8\n",
    "    total_weeks =109\n",
    "    train_size = window_size / 0.2\n",
    "    gap = int((total_weeks - window_size - train_size) // (n_splits))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for split in range(n_splits):\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "\n",
    "        for store_id, group in df.groupby('Store'):\n",
    "            # calculate start and end index for test data\n",
    "            if split == 0:\n",
    "                test_start_index = -window_size\n",
    "                test_df_store = group[test_start_index:]  # Kein Endindex f√ºr den ersten Split\n",
    "            else:\n",
    "                test_start_index = -(window_size + gap * split)\n",
    "                test_end_index = test_start_index + window_size\n",
    "                test_df_store = group[test_start_index:test_end_index]\n",
    "                print(\"test:\", test_df_store.shape, \"Test Start Index:\", test_start_index, \"Test End Index:\", test_end_index)\n",
    "            \n",
    "            train_start_index = -int(-test_start_index + gap + train_size)\n",
    "            train_df_store = group[train_start_index:test_start_index]\n",
    "            print(\"Train:\", train_df_store.shape, \"Train Start Index:\", train_start_index, \"Train End Index:\", test_start_index)\n",
    "            # Check if test set contains data\n",
    "            if not test_df_store.empty:\n",
    "                train_data.append(train_df_store)\n",
    "                test_data.append(test_df_store)\n",
    "            else:\n",
    "                print(f\"Store {store_id} has not enough data for splitting {split}\")\n",
    "\n",
    "        # Combine the list entries to one dataframe\n",
    "        train_df_combined = pd.concat(train_data)\n",
    "        test_df_combined = pd.concat(test_data)\n",
    "\n",
    "        # Create feature and target data frames\n",
    "        X_train = train_df_combined.drop(columns=['Future_Sales'])\n",
    "        y_train = train_df_combined['Future_Sales']\n",
    "        X_test = test_df_combined.drop(columns=['Future_Sales'])\n",
    "        y_test = test_df_combined['Future_Sales']\n",
    "\n",
    "        # Scaling of the data\n",
    "        if scaler:\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "        def adj_r2_score(model, X, y):\n",
    "            n = X.shape[0]\n",
    "            p = X.shape[1]\n",
    "            r2 = r2_score(y, model.predict(X))\n",
    "            return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "    \t# Defining the models to test\n",
    "        models = [\n",
    "            ('LinearRegression', LinearRegression(n_jobs=-1)),\n",
    "            #('RidgeRegression', Ridge(random_state=42)),\n",
    "            #('LassoRegression', Lasso(random_state=42)),\n",
    "            #('DecisionTreeRegressor', DecisionTreeRegressor(random_state=42)),\n",
    "            #('RandomForestRegressor', RandomForestRegressor(n_jobs=-1, max_depth=10, random_state=42, n_estimators=100)),\n",
    "            #('SVR', SVR()),\n",
    "            #('KNN', KNeighborsRegressor())\n",
    "        ]\n",
    "        \n",
    "        # Train models and calculate metrics\n",
    "        for name, model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "        \n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'RMSE_Train': sqrt(mse(y_train, y_train_pred)),\n",
    "                'MAE_Train': mae(y_train, y_train_pred),\n",
    "                'R2_Train': r2_score(y_train, y_train_pred),\n",
    "                'Adj_R2_Train': adj_r2_score(model, X_train, y_train),\n",
    "                'RMSE_Test': sqrt(mse(y_test, y_test_pred)),\n",
    "                'MAE_Test': mae(y_test, y_test_pred),\n",
    "                'R2_Test': r2_score(y_test, y_test_pred),\n",
    "                'Adj_R2_Test': adj_r2_score(model, X_test, y_test)\n",
    "            })\n",
    "            #print last result\n",
    "            print(results[-1])\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # calculate mean of all splits\n",
    "    model_list = results_df['Model'].unique()\n",
    "    # create resulte_mean_df\n",
    "    resulte_mean_df = pd.DataFrame(columns=results_df.columns)\n",
    "    # iterate over model_list\n",
    "    for model in model_list:\n",
    "        # get mean of each model\n",
    "        mean = results_df[results_df['Model'] == model].mean(numeric_only=True)\n",
    "        mean['Model'] = model\n",
    "        # append mean to resulte_mean_df\n",
    "        resulte_mean_df = pd.concat([resulte_mean_df, pd.DataFrame([mean], columns=results_df.columns)], ignore_index=True)\n",
    "\n",
    "    return results_df, resulte_mean_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from pandas.api.types import infer_dtype\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weekly_sales_with_store_info.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Mean reference', 'RMSE_Train': 18049.073796005105, 'MAE_Train': 13313.040861216872, 'R2_Train': -0.018051765838443812, 'RMSE_Test': 16117.825576344818, 'MAE_Test': 11780.306415371311, 'R2_Test': -3.2271684458073935e-07}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>MAE_Test</th>\n",
       "      <th>R2_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean reference</td>\n",
       "      <td>18049.073796</td>\n",
       "      <td>13313.040861</td>\n",
       "      <td>-0.018052</td>\n",
       "      <td>16117.825576</td>\n",
       "      <td>11780.306415</td>\n",
       "      <td>-3.227168e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model    RMSE_Train     MAE_Train  R2_Train     RMSE_Test  \\\n",
       "0  Mean reference  18049.073796  13313.040861 -0.018052  16117.825576   \n",
       "\n",
       "       MAE_Test       R2_Test  \n",
       "0  11780.306415 -3.227168e-07  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test models with test and tain data. Test includes the last 8 weeks from each store\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# Group by store and split into training and test data\n",
    "amount_test_weeks = 8\n",
    "for store_id, group in df.groupby('Store'):\n",
    "    train_data.append(group[: -amount_test_weeks])\n",
    "    test_data.append(group[-amount_test_weeks:])\n",
    "\n",
    "# Combine the list entries to one dataframe\n",
    "train_df = pd.concat(train_data)\n",
    "test_df = pd.concat(test_data)\n",
    "\n",
    "# Create feature and target data frames\n",
    "X_train = train_df\n",
    "y_train = train_df['Sales']\n",
    "X_test = test_df\n",
    "y_test = test_df['Sales']\n",
    "\n",
    "def adj_r2_score(model, X, y):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r2 = r2_score(y, model.predict(X))\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "results = []\n",
    "\n",
    "# Calculate the salces mean and using it as a prediction\n",
    "# df for means of last x weeks\n",
    "timeframeForMean = 12\n",
    "last_day_in_train = X_train['Date'].max()\n",
    "df_X_train_for_means = X_train[X_train['Date'] > last_day_in_train - pd.Timedelta(weeks=timeframeForMean)]\n",
    "mean_sales_train = df_X_train_for_means.mean(numeric_only=True)['Sales']\n",
    "\n",
    "y_train_pred = np.full(y_train.shape, mean_sales_train)\n",
    "y_test_pred = np.full(y_test.shape, mean_sales_train)\n",
    "\n",
    "results.append({\n",
    "    'Model': \"Mean reference\",\n",
    "    'RMSE_Train': sqrt(mse(y_train, y_train_pred)),\n",
    "    'MAE_Train': mae(y_train, y_train_pred),\n",
    "    'R2_Train': r2_score(y_train, y_train_pred),\n",
    "    #'Adj_R2_Train': adj_r2_score(model, X_train, y_train),\n",
    "    'RMSE_Test': sqrt(mse(y_test, y_test_pred)),\n",
    "    'MAE_Test': mae(y_test, y_test_pred),\n",
    "    'R2_Test': r2_score(y_test, y_test_pred),\n",
    "    #'Adj_R2_Test': adj_r2_score(model, X_test, y_test)\n",
    "})\n",
    "#print last result\n",
    "print(results[-1])\n",
    "\n",
    "# Konvertieren Sie die Liste von Dictionaries in einen DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:**  \n",
    "-> The MAE of the simple mean forecast is 11780.306415"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_nans_handeled_cat_power.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LinearRegression', 'RMSE_Train': 9081.178921413037, 'MAE_Train': 6229.184072093825, 'R2_Train': 0.7515692210307627, 'Adj_R2_Train': 0.7511593471555716, 'RMSE_Test': 5941.163691018397, 'MAE_Test': 4395.438901345292, 'R2_Test': 0.8641279045091326, 'Adj_R2_Test': 0.8611545348667453}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>Adj_R2_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>MAE_Test</th>\n",
       "      <th>R2_Test</th>\n",
       "      <th>Adj_R2_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>9081.178921</td>\n",
       "      <td>6229.184072</td>\n",
       "      <td>0.751569</td>\n",
       "      <td>0.751159</td>\n",
       "      <td>5941.163691</td>\n",
       "      <td>4395.438901</td>\n",
       "      <td>0.864128</td>\n",
       "      <td>0.861155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   RMSE_Train    MAE_Train  R2_Train  Adj_R2_Train  \\\n",
       "0  LinearRegression  9081.178921  6229.184072  0.751569      0.751159   \n",
       "\n",
       "     RMSE_Test     MAE_Test   R2_Test  Adj_R2_Test  \n",
       "0  5941.163691  4395.438901  0.864128     0.861155  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModelsTestSplit8W(df, MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
