{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Projekt Rossmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of models that will be tested to predict the sales of Rossmann stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Models:\n",
    "\n",
    "Linear Regression: If the relationship between the predictors and the sales is linear, linear regression can be a good starting point.\n",
    "Ridge/Lasso Regression: These are variations of linear regression that include regularization to prevent overfitting, especially useful if you have many predictors.\n",
    "Tree-based Models:\n",
    "\n",
    "Decision Trees: Good for capturing non-linear relationships but can overfit.\n",
    "Random Forest: An ensemble of decision trees, it is more robust and less likely to overfit than a single decision tree.\n",
    "Gradient Boosting Machines (GBM): Models like Gradient Boosting Regressor or XGBoost, LightGBM, and CatBoost are powerful for capturing complex patterns in data.\n",
    "Support Vector Machines (SVM):\n",
    "\n",
    "SVR (Support Vector Regression): Effective in high-dimensional spaces and with kernel functions, it can capture complex relationships.\n",
    "Nearest Neighbors:\n",
    "\n",
    "K-Nearest Neighbors (KNN): Can be used for regression; it predicts the value based on the 'k' closest points.\n",
    "Time Series Specific Models (Not in Scikit-learn but worth considering):\n",
    "\n",
    "ARIMA/SARIMA: Traditional time series models suitable for univariate time series.\n",
    "Prophet: Developed by Facebook, good for daily data with multiple seasonality and holiday effects.\n",
    "LSTM/GRU (Deep Learning): RNNs like LSTM or GRU can be effective, especially if you have a large amount of historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression Models:  \n",
    "\t- Linear Regression\n",
    "\t- Ridge Regression\n",
    "\t- Lasso Regression\n",
    "\n",
    "- Tree-based Models:\n",
    "\t- Decision Trees\n",
    "\t- Random Forest\n",
    "\t- Gradient Boosting Machines (GBM) (in scikit-learn: GradientBoostingRegressor)\n",
    "\n",
    "- Support Vector Machines (SVM):\n",
    "\t- SVR (Support Vector Regression)\n",
    "\n",
    "- Nearest Neighbors:\n",
    "\t- K-Nearest Neighbors (KNN)\n",
    "\n",
    "- Neural Networks:\n",
    "\t- MLP (Multi-layer Perceptron)\n",
    "\n",
    "- Time Series Specific Models:\n",
    "\t- ARIMA/SARIMA\n",
    "\t- Prophet\n",
    "\t- LSTM/GRU (Deep Learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use:\n",
    "- LinearRegression\n",
    "- RidgeRegression\n",
    "- LassoRegression\n",
    "- DecisionTreeRegressor\n",
    "- RandomForestRegressor\n",
    "- GradiantBoostingRegressor\n",
    "- SVR\n",
    "- KNN\n",
    "- MLPRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of KPIs for model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Absolute Error (MAE): The average of the absolute differences between predictions and actual values. It gives an idea of the magnitude of the error, but no information about the direction (over or under predicting).\n",
    "- Mean Squared Error (MSE): The average of the squared differences between predictions and actual values. It gives more weight to larger errors and is more useful in practice than MAE.\n",
    "- Root Mean Squared Error (RMSE): The square root of the MSE, it is more interpretable than the MSE as it is in the same units as the response variable.\n",
    "- R-squared (R2): The proportion of the variance in the dependent variable that is predictable from the independent variables. It provides an indication of the goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.\n",
    "- Adjusted R-squared: The R-squared value adjusted for the number of predictors in the model. It is useful for comparing models with different numbers of predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2  Feature3  Target\n",
      "0  0.548814         2 -1.029392       0\n",
      "1  0.715189         7 -0.386121       1\n",
      "2  0.602763         6  0.539313       0\n",
      "3  0.544883         5 -0.415789       1\n",
      "4  0.423655         5 -0.718476       0\n",
      "Feature-Matrix (X):\n",
      "   Feature1  Feature2  Feature3\n",
      "0  0.548814         2 -1.029392\n",
      "1  0.715189         7 -0.386121\n",
      "2  0.602763         6  0.539313\n",
      "3  0.544883         5 -0.415789\n",
      "4  0.423655         5 -0.718476\n",
      "\n",
      "Zielvektor (y):\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: Target, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Einstellen des Zufallsgenerators für Reproduzierbarkeit\n",
    "np.random.seed(0)\n",
    "\n",
    "# Erstellen eines DataFrame mit 100 Zeilen und 4 Spalten\n",
    "n_rows = 1000\n",
    "df = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(n_rows),  # Zufällige Werte zwischen 0 und 1\n",
    "    'Feature2': np.random.randint(1, 10, size=n_rows),  # Zufällige ganze Zahlen zwischen 1 und 9\n",
    "    'Feature3': np.random.randn(n_rows),  # Zufällige Werte aus einer Normalverteilung\n",
    "    'Target': np.random.randint(0, 2, size=n_rows)  # Binäre Zielvariable (0 oder 1)\n",
    "})\n",
    "\n",
    "X = df[['Feature1', 'Feature2', 'Feature3']]\n",
    "y = df['Target']\n",
    "\n",
    "print(df.head())  # Anzeigen der ersten 5 Zeilen des DataFrame\n",
    "print(\"Feature-Matrix (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nZielvektor (y):\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>Adj_R2_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>MAE_Test</th>\n",
       "      <th>R2_Test</th>\n",
       "      <th>Adj_R2_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.499868</td>\n",
       "      <td>0.499735</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>0.500522</td>\n",
       "      <td>0.500388</td>\n",
       "      <td>-0.002490</td>\n",
       "      <td>-0.017834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeRegression</td>\n",
       "      <td>0.499868</td>\n",
       "      <td>0.499735</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>-0.003243</td>\n",
       "      <td>0.500527</td>\n",
       "      <td>0.500393</td>\n",
       "      <td>-0.002508</td>\n",
       "      <td>-0.017853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LassoRegression</td>\n",
       "      <td>0.499998</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003769</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.500025</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-0.015820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.655744</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>-0.720688</td>\n",
       "      <td>-0.747025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.199980</td>\n",
       "      <td>0.185588</td>\n",
       "      <td>0.840032</td>\n",
       "      <td>0.839429</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>-0.058663</td>\n",
       "      <td>-0.074867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.552320</td>\n",
       "      <td>0.481259</td>\n",
       "      <td>-0.220236</td>\n",
       "      <td>-0.224835</td>\n",
       "      <td>0.580585</td>\n",
       "      <td>0.513486</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.369499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.447661</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.198395</td>\n",
       "      <td>0.195374</td>\n",
       "      <td>0.548635</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>-0.204482</td>\n",
       "      <td>-0.222918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  RMSE_Train  MAE_Train  R2_Train  Adj_R2_Train  \\\n",
       "0       LinearRegression    0.499868   0.499735  0.000523     -0.003243   \n",
       "1        RidgeRegression    0.499868   0.499735  0.000523     -0.003243   \n",
       "2        LassoRegression    0.499998   0.499997  0.000000     -0.003769   \n",
       "3  DecisionTreeRegressor    0.000000   0.000000  1.000000      1.000000   \n",
       "4  RandomForestRegressor    0.199980   0.185588  0.840032      0.839429   \n",
       "5                    SVR    0.552320   0.481259 -0.220236     -0.224835   \n",
       "6                    KNN    0.447661   0.397500  0.198395      0.195374   \n",
       "\n",
       "   RMSE_Test  MAE_Test   R2_Test  Adj_R2_Test  \n",
       "0   0.500522  0.500388 -0.002490    -0.017834  \n",
       "1   0.500527  0.500393 -0.002508    -0.017853  \n",
       "2   0.500027  0.500025 -0.000506    -0.015820  \n",
       "3   0.655744  0.430000 -0.720688    -0.747025  \n",
       "4   0.514354  0.477700 -0.058663    -0.074867  \n",
       "5   0.580585  0.513486 -0.348854    -0.369499  \n",
       "6   0.548635  0.497000 -0.204482    -0.222918  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# Erstellen eines Beispieldatenrahmens\n",
    "np.random.seed(0)\n",
    "n_rows = 1000\n",
    "df = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(n_rows),\n",
    "    'Feature2': np.random.randint(1, 10, size=n_rows),\n",
    "    'Feature3': np.random.randn(n_rows),\n",
    "    'Target': np.random.randint(0, 2, size=n_rows)\n",
    "})\n",
    "\n",
    "# Aufteilen in Features (X) und Zielvariable (y)\n",
    "feature_columns = df.columns.difference(['Target'])\n",
    "X = df[feature_columns]\n",
    "y = df['Target']\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Funktion zur Berechnung des angepassten R2\n",
    "def adj_r2_score(model, X, y):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r2 = r2_score(y, model.predict(X))\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "# Modelle definieren\n",
    "models = [\n",
    "    ('LinearRegression', LinearRegression()),\n",
    "    ('RidgeRegression', Ridge()),\n",
    "    ('LassoRegression', Lasso()),\n",
    "    ('DecisionTreeRegressor', DecisionTreeRegressor()),\n",
    "    ('RandomForestRegressor', RandomForestRegressor()),\n",
    "    ('SVR', SVR()),\n",
    "    ('KNN', KNeighborsRegressor())\n",
    "]\n",
    "\n",
    "# Ergebnis-DataFrame vorbereiten\n",
    "results = []\n",
    "\n",
    "# Modelle trainieren und Metriken auswerten\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'RMSE_Train': sqrt(mse(y_train, y_train_pred)),\n",
    "        'MAE_Train': mae(y_train, y_train_pred),\n",
    "        'R2_Train': r2_score(y_train, y_train_pred),\n",
    "        'Adj_R2_Train': adj_r2_score(model, X_train, y_train),\n",
    "        'RMSE_Test': sqrt(mse(y_test, y_test_pred)),\n",
    "        'MAE_Test': mae(y_test, y_test_pred),\n",
    "        'R2_Test': r2_score(y_test, y_test_pred),\n",
    "        'Adj_R2_Test': adj_r2_score(model, X_test, y_test)\n",
    "    })\n",
    "\n",
    "# Konvertieren Sie die Liste von Dictionaries in einen DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nutzt gesplitte daten in einmaligen test und train wobei test die letzten 8 wochen jedes stores beinhaltet\n",
    "##\n",
    "##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten\n",
    "# Listen, um die Trainings- und Testdaten zu speichern\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# Gruppieren nach Store und Aufteilen in Trainings- und Testdaten\n",
    "amount_test_weeks = 8\n",
    "for store_id, group in df.groupby('Store'):\n",
    "    train_data.append(group[: -amount_test_weeks])\n",
    "    test_data.append(group[-amount_test_weeks:])\n",
    "\n",
    "# Kombinieren der Trainings- und Testdaten\n",
    "train_df = pd.concat(train_data)\n",
    "test_df = pd.concat(test_data)\n",
    "\n",
    "X_train = train_df\n",
    "y_train = train_df['Sales']\n",
    "X_test = test_df\n",
    "y_test = test_df['Sales']\n",
    "\n",
    "\n",
    "# Funktion zur Berechnung des angepassten R2\n",
    "def adj_r2_score(model, X, y):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r2 = r2_score(y, model.predict(X))\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "\n",
    "# Ergebnis-DataFrame vorbereiten\n",
    "results = []\n",
    "\n",
    "# Calculate the salces mean and using it as a prediction\n",
    "# df for means of last x weeks\n",
    "timeframeForMean = 12\n",
    "last_day_in_train = X_train['Date'].max()\n",
    "df_X_train_for_means = X_train[X_train['Date'] > last_day_in_train - pd.Timedelta(weeks=timeframeForMean)]\n",
    "mean_sales_train = df_X_train_for_means.mean(numeric_only=True)['Sales']\n",
    "#mean_sales_test = X_test['Sales'].mean()\n",
    "\n",
    "y_train_pred = np.full(y_train.shape, mean_sales_train)\n",
    "y_test_pred = np.full(y_test.shape, mean_sales_train)\n",
    "\n",
    "results.append({\n",
    "    'Model': \"Mean reference\",\n",
    "    'RMSE_Train': sqrt(mse(y_train, y_train_pred)),\n",
    "    'MAE_Train': mae(y_train, y_train_pred),\n",
    "    'R2_Train': r2_score(y_train, y_train_pred),\n",
    "    #'Adj_R2_Train': adj_r2_score(model, X_train, y_train),\n",
    "    'RMSE_Test': sqrt(mse(y_test, y_test_pred)),\n",
    "    'MAE_Test': mae(y_test, y_test_pred),\n",
    "    'R2_Test': r2_score(y_test, y_test_pred),\n",
    "    #'Adj_R2_Test': adj_r2_score(model, X_test, y_test)\n",
    "})\n",
    "#print last result\n",
    "print(results[-1])\n",
    "\n",
    "# Konvertieren Sie die Liste von Dictionaries in einen DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
